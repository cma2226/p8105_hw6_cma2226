---
title: "Homework 6"
author: "Caroline Andy"
date: "12/6/2020"
output: github_document
---

### Problem 1

```{r load, warning = FALSE, message = FALSE}
library(purrr)
library(tidyverse)
library(stringr)
library(patchwork)
library(skimr)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

For this problem, I will use a dataset containing reported homicides in 50 large U.S. cities. I will first clean the data, creating a city-state variable, revaluing disposition, and removing cities that do not report homicide race data. 

```{r, warning = FALSE, message = FALSE}
#generate homicide table and summarize solved and unsolved murders by state
homicide = 
  read_csv("homicide-data.csv", na = c("", "NA", "Unknown")) %>%
  drop_na() %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    victim_sex = as.factor(victim_sex),
    resolution = case_when(
      disposition %in% "Closed without arrest" ~ 0,
      disposition %in% "Closed by arrest" ~ 1, 
      disposition %in% "Open/No arrest" ~ 0)) %>%
  filter(
    victim_race %in% c("White", "Black"),
    !(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) %>%
  mutate(
    victim_race = as.factor(victim_race),
    victim_race = as.character(victim_race),
    victim_sex = as.character(victim_sex)
  ) %>%
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Now I will use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors for the city of Baltimore, MD, 

```{r, warning = FALSE, message = FALSE}
baltimore_df = 
  homicide %>%
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df, 
    family = binomial()) %>%
  broom::tidy() %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(term, OR, starts_with("CI")) %>%
  knitr::kable(digits = 3)
```

Now I will run glm for each of the cities in my dataset, and extract the adjusted odds ratio and confidence interval (CI) for solving homicides comparing Black victims to White victims.

```{r, warning = FALSE, message = FALSE}
model_results_df = 
  homicide %>%
  nest(data = -city_state) %>%
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
    results = map(models, broom::tidy)
) %>%
  select(city_state, results) %>%
  unnest(results) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(city_state, term, OR, starts_with("CI"))
```

The below plot shows the estimated odds ratios and CIs for White race (as compared to Black race as the reference category) for each city.

```{r, warning = FALSE, message = FALSE}
model_results_df %>%
  filter(term == "victim_raceWhite") %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Overall, these results show that White race is associated with 2.320 times the odds of having a resolved homicide as compared to Black race. In particular, this disparity is the largest in Boston, MA, where white race is associated with over 10 times the odds of having a resolved homicide as compared to Black race. This disparity is the lowest in Tampa, Florida.

### Problem 2

In this problem, I will analyze data gathered to understand the effects of several variables on a childâ€™s birthweight. This dataset consists of roughly 4000 children and includes 20 variables, including baby sex, head circumference, length, gestational age, and mother's age, age at menarche, height, race and previous pregnancy outcomes. 

Here I will load and clean the data for regression analysis, converting numeric variables to factor variables where appropriate, and checking for missing values. 

```{r, message = FALSE, warning = FALSE}
bweight = read_csv("./birthweight.csv")
skim(bweight) 
# no missing values, all variables are numeric

# convert sex, race and malformation variable to factors
bweight = bweight %>%
  mutate(babysex = (fct_infreq(as.factor(babysex))),
         frace = (fct_infreq(as.factor(frace))),
         mrace = (fct_infreq(as.factor(mrace))),
         malform = (fct_infreq(as.factor(malform)))) 
```

Now I will propose a regression model for birthweight using backwards stepwise selection with the step() function. 

```{r, message = FALSE, warning = FALSE}
## function for backward stepwise selection
mult.fit <- lm(bwt ~ ., data = bweight)
step(mult.fit, direction = 'backward')

## final proposed model based on backward stepwise selection: 
reg = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    mheight + mrace + parity + ppwt + smoken, data = bweight)
```

Backward selection is a method of model variable selection in which the least significant predictors are sequentially removed from the model until only significant predictors remain. This is the approach I adopted in developing my linear regression model. My final model contains the following predictors:

- baby sex
- baby head circumference
- baby length
- mother's weight at delivery
- family monthly income
- gestational age
- mother's height
- mother's race
- number of lives births prior to this pregnancy
- mother's pre-pregnancy weight, and 
- average number of cigarettes smoked per day during pregnancy

We can graph the residuals against x values to see if there are any emergent trends.

```{r, message = FALSE, warning = FALSE}
bweight = modelr::add_residuals(bweight, reg)
modelr::add_predictions(bweight, reg) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point()
```

The plot shows that the majority of values are centered around a residual value of 0 within the range of predicted values between 2000 and 4000. There is no pattern in the residuals for this range of x values. As the predicted weight values get very small, however, we see higher residual values. This suggests that this model may perform well for average and above average weight babies, but not as well for lower weight babies. 

Now I will generate two additional models to compare my model to. These include: (1) a simple model containing only baby length and gestational week as predictors, and (2) a model containing baby length, head circumference, sex, and the three-way interactions of these variables. 

```{r, message = FALSE, warning = FALSE}
## Predictors = length and gesitational age 
simple = lm(bwt ~ blength + gaweeks, data = bweight)
simple %>%
  broom::glance()
## Adjusted R squared = 0.5767

## Predictors = head circumference, length, sex and all interactions
interaction = lm(bwt ~ blength*bhead*babysex, data = bweight)
interaction %>%
  broom::glance()
## Adjusted R squared = 0.6844 
```

Now I will compare these models in terms of the cross-validated prediction error.

```{r, message = FALSE, warning = FALSE}
# use crossv_mc function to partition the data for a test-training split
cv_df = 
  crossv_mc(bweight, 4342) 

# format the training and testing data as tibbles
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

# generate model outputs and rmse for each model
cv_df = 
  cv_df %>% 
  mutate(
    simple_mod  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    interaction_mod = map(train, ~lm(bwt ~ blength*bhead*babysex, data = .x)), 
    my_mod  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    mheight + mrace + parity + ppwt + smoken, data = .x))) %>% 
  mutate(
    rmse_simple = map2_dbl(simple_mod, test, ~rmse(model = .x, data = .y)),
    rmse_interaction = map2_dbl(interaction_mod, test, ~rmse(model = .x, data = .y)),
    rmse_backward_step = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)))
```

Now I will generate a plot of model residuals against fitted values for each model. 

```{r, message = FALSE, warning = FALSE}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "RMSE by model",
    x = "Model type",
    y = "RMSE"
  )
```

As we can see from this plot, the model made through backward stepwise selection has the lowest RMSE. Thus, this model has the best performance in predicting baby weight. While the simple model is the most parsimonious, its RMSE is substantially higher than the other two models. The interaction model not only has a higher RMSE than the backward stepwise selection model, but it also is less easily interpretable as it involves the threeway interactions between baby head circumference, length, sex. 

### Problem 3

For this problem, I will use a dataset documenting weather observed in Central Park. We are interested in predicting the daily reported temperature maximum using the reported temperature minimum as a predictor. First I will load and clean the dataset, and generate a simple linear regression model containing mininum temperature as the predictor and maximum temperature as the outcome. 

```{r, message = FALSE, warning = FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

# regression model for 1 (weather_df) sample
lm(tmax ~ tmin, data = weather_df) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Now I will draw 5000 bootstrap samples from the weather dataset, and will run the above linear regression model on each dataset to generate estimates for $\hat r^2$ and $log(\beta_0*\beta_1)$ for each bootstrap. 

```{r, message = FALSE, warning = FALSE}
# draw one bootstrap sample
set.seed(1)

boot_sample = function(df) {
  sample_frac(weather_df, replace = TRUE)
}

# draw 5000 bootstrap samples
boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

# run regression models on 5000 bootstrap samples 
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results1 = map(models, broom::glance),
    results2 = map(models, broom::tidy)) %>% 
  select(strap_number, results1, results2) %>% 
  unnest(results1, results2) 
```

We may calculate the mean $\hat r^2$ over all bootstrap samples as follows:

```{r, message = FALSE, warning = FALSE}
# find mean r squared over all bootstrap samples
bootstrap_results %>%
  summarize(mean_r_sq = mean(r.squared))
```

Now I will generate the $log(\beta_0*\beta_1)$ variable using estimates for $\beta_0$ and $\beta_1$ for each bootstrap sample.

```{r, message = FALSE, warning = FALSE}
# generate log(B0*B1) variable
btstrap_log_data = 
  bootstrap_results %>%
  select(strap_number, term, estimate) %>%
  pivot_wider(
    names_from = term,
    values_from = estimate) %>%
  rename("B0" = "(Intercept)",
         "B1" = "tmin") %>%
  mutate(
    log_var = log(B0*B1)
  )
```

We may calculate the mean $log(\beta_0*\beta_1)$ over all bootstrap samples as follows:

```{r, message = FALSE, warning = FALSE}
# find log(B0*B1) over all bootstrap samples
btstrap_log_data %>%
  summarize(mean_log_var = mean(log_var))
```

Now I will generate a plot of the distribution of the r squared estimate over all bootstrap samples. 

```{r, message = FALSE, warning = FALSE}
bootstrap_results %>%
  ggplot(aes(x = r.squared)) +
  geom_density(alpha = .4, adjust = .5, color = "blue")
```

The density plot of r squared estimates is centered around 0.91, which is consistent with the calculated mean estimate, 0.9113306. The distribution of the r squared estimate appears to be normal, though shows heavy tails and slight left skewness.

Now I will generate a plot of the distribution of the $log(\beta_0*\beta_1)$ estimate over all bootstrap samples. 

```{r, message = FALSE, warning = FALSE}
btstrap_log_data %>%
  ggplot(aes(x = log_var)) +
  geom_density(alpha = .4, adjust = .5, color = "blue")
```

The density plot of $log(\beta_0*\beta_1)$ estimates is centered around 2.01, which is consistent with the calculated mean estimate, 2.013103. The distribution of the $log(\beta_0*\beta_1)$ estimate appears to be normal.

Using the 5000 bootstrap estimates, I will now identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for $\hat r^2$ and $log(\beta_0*\beta_1)$.

```{r, message = FALSE, warning = FALSE}
## r^2 95% CI
bootstrap_results %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))

## log(B0*B1) 95% CI
btstrap_log_data %>% 
  summarize(
    ci_lower = quantile(log_var, 0.025), 
    ci_upper = quantile(log_var, 0.975))
```

Thus, the mean estimate and 95% confidence interval for $\hat r^2$ is 0.9113306 (0.8936684, 0.927106). The mean estimate and 95% confidence interval for $log(\beta_0*\beta_1)$ is 2.013103 (1.964949, 2.058887). 
